<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Applied Econometrics with R (online) - 2&nbsp; Regression Analysis in the Social Sciences</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./multivariate.html" rel="next">
<link href="./intro.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>
window.MathJax = {
  tex: {
    tags: 'ams'
  }
};
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./linear_regression.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Regression Analysis in the Social Sciences</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Applied Econometrics with <code>R</code> (online)</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear_regression.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Regression Analysis in the Social Sciences</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./multivariate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Modeling in the Social Sciences</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./assessment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Specification and Assessment Issues</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">In conclusion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Reviewing probability and statistics</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">2.1</span> Introduction</a></li>
  <li><a href="#sec-problem" id="toc-sec-problem" class="nav-link" data-scroll-target="#sec-problem"><span class="header-section-number">2.2</span> So, what is the problem?</a>
  <ul>
  <li><a href="#a-first-encounter-with-r" id="toc-a-first-encounter-with-r" class="nav-link" data-scroll-target="#a-first-encounter-with-r"><span class="header-section-number">2.2.1</span> A first encounter with <code>R</code></a></li>
  <li><a href="#sec-numevidence" id="toc-sec-numevidence" class="nav-link" data-scroll-target="#sec-numevidence"><span class="header-section-number">2.2.2</span> Numerical evidence</a>
  <ul class="collapse">
  <li><a href="#estimation" id="toc-estimation" class="nav-link" data-scroll-target="#estimation"><span class="header-section-number">2.2.2.1</span> Estimation</a></li>
  <li><a href="#hypothesis-testing" id="toc-hypothesis-testing" class="nav-link" data-scroll-target="#hypothesis-testing"><span class="header-section-number">2.2.2.2</span> Hypothesis testing</a></li>
  <li><a href="#confidence-interval" id="toc-confidence-interval" class="nav-link" data-scroll-target="#confidence-interval"><span class="header-section-number">2.2.2.3</span> Confidence interval</a></li>
  </ul></li>
  <li><a href="#sec-smart" id="toc-sec-smart" class="nav-link" data-scroll-target="#sec-smart"><span class="header-section-number">2.2.3</span> Always be smart (and a bit lazy)</a></li>
  </ul></li>
  <li><a href="#sec-uniregress" id="toc-sec-uniregress" class="nav-link" data-scroll-target="#sec-uniregress"><span class="header-section-number">2.3</span> Univariate regression</a>
  <ul>
  <li><a href="#sec-genesis" id="toc-sec-genesis" class="nav-link" data-scroll-target="#sec-genesis"><span class="header-section-number">2.3.1</span> Genesis: <em>regression towards the mean</em></a></li>
  <li><a href="#regression-with-one-regressor" id="toc-regression-with-one-regressor" class="nav-link" data-scroll-target="#regression-with-one-regressor"><span class="header-section-number">2.3.2</span> Regression with one regressor</a>
  <ul class="collapse">
  <li><a href="#estimating-with-ols" id="toc-estimating-with-ols" class="nav-link" data-scroll-target="#estimating-with-ols"><span class="header-section-number">2.3.2.1</span> Estimating with OLS</a></li>
  <li><a href="#sec-unitesting" id="toc-sec-unitesting" class="nav-link" data-scroll-target="#sec-unitesting"><span class="header-section-number">2.3.2.2</span> Hypothesis testing</a></li>
  <li><a href="#confidence-intervals" id="toc-confidence-intervals" class="nav-link" data-scroll-target="#confidence-intervals"><span class="header-section-number">2.3.2.3</span> Confidence intervals</a></li>
  <li><a href="#sec-dummy" id="toc-sec-dummy" class="nav-link" data-scroll-target="#sec-dummy"><span class="header-section-number">2.3.2.4</span> Regression with a dummy</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-lsa" id="toc-sec-lsa" class="nav-link" data-scroll-target="#sec-lsa"><span class="header-section-number">2.4</span> Least squares assumptions for causal inference</a>
  <ul>
  <li><a href="#least-squares-assumption-1-conditional-mean-independence" id="toc-least-squares-assumption-1-conditional-mean-independence" class="nav-link" data-scroll-target="#least-squares-assumption-1-conditional-mean-independence"><span class="header-section-number">2.4.1</span> Least squares assumption 1: conditional mean independence</a></li>
  <li><a href="#least-squares-assumption-2-independenty-and-identically-distributed" id="toc-least-squares-assumption-2-independenty-and-identically-distributed" class="nav-link" data-scroll-target="#least-squares-assumption-2-independenty-and-identically-distributed"><span class="header-section-number">2.4.2</span> Least squares assumption 2: independenty and identically distributed</a></li>
  <li><a href="#least-squares-assumption-3-large-outliers-are-rare" id="toc-least-squares-assumption-3-large-outliers-are-rare" class="nav-link" data-scroll-target="#least-squares-assumption-3-large-outliers-are-rare"><span class="header-section-number">2.4.3</span> Least squares assumption 3: Large outliers are rare</a></li>
  </ul></li>
  <li><a href="#other-least-squares-assumptions" id="toc-other-least-squares-assumptions" class="nav-link" data-scroll-target="#other-least-squares-assumptions"><span class="header-section-number">2.5</span> Other least squares assumptions</a>
  <ul>
  <li><a href="#homoskedasticity" id="toc-homoskedasticity" class="nav-link" data-scroll-target="#homoskedasticity"><span class="header-section-number">2.5.1</span> Homoskedasticity</a></li>
  <li><a href="#normal-distributed-regression-term" id="toc-normal-distributed-regression-term" class="nav-link" data-scroll-target="#normal-distributed-regression-term"><span class="header-section-number">2.5.2</span> Normal distributed regression term</a></li>
  </ul></li>
  <li><a href="#measures-of-fit" id="toc-measures-of-fit" class="nav-link" data-scroll-target="#measures-of-fit"><span class="header-section-number">2.6</span> Measures of fit</a>
  <ul>
  <li><a href="#the-regression-r2" id="toc-the-regression-r2" class="nav-link" data-scroll-target="#the-regression-r2"><span class="header-section-number">2.6.1</span> The regression R<span class="math inline">\(^2\)</span></a></li>
  <li><a href="#the-standard-error-of-the-regression" id="toc-the-standard-error-of-the-regression" class="nav-link" data-scroll-target="#the-standard-error-of-the-regression"><span class="header-section-number">2.6.2</span> The Standard Error of the Regression</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">2.7</span> Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-univariateregression" class="quarto-section-identifier"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Regression Analysis in the Social Sciences</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level2 page-columns page-full" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">2.1</span> Introduction</h2>
<p>Why should we have something as applied econometrics in the social sciences? That is because we have theories and those theories contain variables such as in the direct utility function of model (<span class="math inline">\(\ref{eq:directutility}\)</span>):</p>
<p><span class="math display">\[\begin{equation}
U(x_1, x2) = x_1^\alpha \cdot x_2^\beta
\label{eq:directutility}
\end{equation}\]</span></p>
<p>Here, the quantities of the goods <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are considered to be <strong>known</strong>—also often referred to as <strong>data</strong>. In theoretical work they are fictional or sometimes simulated. The parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are <strong>not known</strong> and we often want to <strong>estimate</strong> them. If we know what the parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> should be, then we can calculate what utility a certain amount of consumption of both goods gives and then, for example, assess which combination of goods gives maximum utility.</p>
<div class="page-columns page-full"><p>This course is about using data to quantify (socio-economic) parameters. Moreover, we focus on measuring <strong>causal</strong> effects, instead of mere correlations. Note, that in an ideal world, we would like conducting experiments as to measure a causal relation of a phenomenon <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. However, we almost always only have observational data on, for example, demand and prices. Therefore, this course and syllabus deals with (<em>i</em>) difficulties arising from using observational data to estimate these causal effects and (<em>ii</em>) rewriting models as (<span class="math inline">\(\ref{eq:directutility}\)</span>) such that we can actually <em>use</em> data to tease out values for—in this case—<span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">Moreover, very often experiments are not feasible or highly unethical.</span></div></div>
<p>This chapter is organised as follows. The next section addresses the problem of finding a <em>relation</em> between some <span class="math inline">\(X\)</span> and some <span class="math inline">\(Y\)</span>. Here, we follow an example from the well-known textbook of <span class="citation" data-cites="stock2003introduction">Stock, Watson, et al. (<a href="references.html#ref-stock2003introduction" role="doc-biblioref">2003</a>)</span> where we look at the relation between school class size and school class performance. At the same time, we also introduce some <code>R</code> commands. To do so, this section deals as well with the statistical framework that is needed for applied econometrics. Note that we assume that the reader already had a course in introductionary statistics and that we provide only the basic concepts most important for this course in <a href="appendix.html" class="quarto-xref"><span>Appendix A</span></a>.</p>
</section>
<section id="sec-problem" class="level2 page-columns page-full" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="sec-problem"><span class="header-section-number">2.2</span> So, what is the problem?</h2>
<p>As explained in the introduction above, applied econometrics aims to give the policy maker well-informed, and evidence based, values for variables she needs. She needs these variables basically for two separate things:</p>
<ol type="1">
<li><strong>Causal inference</strong>: The policy maker wants to assess the effect of a change in one variable (typically called <span class="math inline">\(X\)</span>) on another variables (often called <span class="math inline">\(Y\)</span>).</li>
<li><strong>Prediction</strong>: If you know what variable <span class="math inline">\(X\)</span> is, what should <span class="math inline">\(Y\)</span> then be?</li>
</ol>
<p>Nowadays, most applied econometric techniques are concerned with causal inference, not so much with prediction. Even more, the techniques often applied are beneficial for correct causal inference, but might harm prediction. However, see that without correct causal inference (so knowing the <strong>true</strong> causal mechanism) prediction is always cumbersome. That is why current methods such as machine learning methods first focus on finding the correct causal mechanism (even without sometimes specifying what they may be) and then optimize prediction.</p>
<p>Thus, finding (causal) mechanism helps the scientist or policy maker in assessing the outcomes of a particular (policy) intervention. In the economic realm one could think about trying to assess the following quantities:</p>
<ul>
<li>To what extent do people eat less meat if we increase the prices with 1% (using a meat-tax)?</li>
<li>If we increase Dutch dikes with one meter, how much less flood risk will there be?</li>
<li>How much do classes perform better is we reduce class-size with one student?</li>
</ul>
<section id="a-first-encounter-with-r" class="level3 page-columns page-full" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="a-first-encounter-with-r"><span class="header-section-number">2.2.1</span> A first encounter with <code>R</code></h3>
<div class="page-columns page-full"><p>For this section, we will focus on the last question. And this is an important question for policy as teachers are costly, but parents value school performance very highly. To start answering this question we <em>use</em> data. In <code>R</code> data can be in many formats, but usually is in a text file, often with the extension <code>.csv</code>. The good thing about this format is that it can always be read with every computer and every operating system. To start using <code>R</code> we first need to set the working directory to the appropriate directory. You can do this by using the following command:</p><div class="no-row-height column-margin column-container"><span class="margin-aside"><code>.csv</code> stands for comma seperated value and is just a text file commas denoting the columns.</span><span class="margin-aside">I suggest that for this—and every other course—you have a specific directory</span></div></div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">setwd</span>(<span class="st">"/Users/tomba/Library/CloudStorage/OneDrive-VrijeUniversiteitAmsterdam/Thomas/project/preparatory"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note here that this file path is used on an Apple or Linux system. On a Windows system you need forward slashes. It is also good to have subdirectories in your project/course folder for e.g.&nbsp;slides, data and tutorials. Already a couple of things can be noticed from this command. We set a working directory with <code>setwd</code> and afterwards we put the path in parentheses (that is now known as the argument from the <code>setwd</code> command). Moreover, because we are working with text (a so-called string variable), the path has to be in quotation marks.</p>
<div class="page-columns page-full"><p>Now suppose you have the subdirectory <code>data</code> in your course folder and in that data directory you have a file called <code>CASchools.csv</code>. Now, this dataset describes 420 school districts in California and, amongst other things, their average performance (measured by a test score) and their financial constraints (measured by the amount of students per teacher).</p><div class="no-row-height column-margin column-container"><span class="margin-aside">Often it is as well advisable to make a distinction between <em>derived</em> and <em>raw</em> data. Raw data is original data and derived data is data you have transformed or worked on. In principle, you do not want to change the original data!</span><span class="margin-aside">This dataset can be downloaded from Canvas as well with already the data transformed.</span></div></div>
<p>To import the data in <code>R</code> you make use of the <code>read.csv</code> command, as follows:</p>
<div class="cell" data-collectcode="true">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Read in CASchools dataset</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>CASchools <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"./data/CASchools.csv"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that we can comment on our code by the use of the <code>#</code>-sign. Everything after will not be used for computation. And I advise you to regularly comment on your code as that makes it easier for somebody and future you to understand the code. Moreover, the <code>&lt;-</code> symbol indicated that the output of the command on the right hand side is poured into a new object (somethings we conveniently in this case call <code>CASchools</code> as well) on the left hand side of this symbol. This object is now a so-called dataframe which you can open in, e.g., RStudio. To some extent it resembles the <code>Excel</code> set-up with observations in rows and variables in the columns.</p>
<div class="page-columns page-full"><p>For our purpose a much quicker way to load the <code>CASchools.csv</code> dataset is to use the <code>AER</code> package that contains many datasets that are often used for educational purposes.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">But note that some data in this particular <code>CASchools</code> file still has to be transformed which I will do below.</span></div></div>
<div class="cell" data-collectcode="true">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># First, invoke the library AER</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># (at the beginning of each session you have to do this)</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># (you also have to install packages which you can do using the package pane in the right-bottom panel)</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AER)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(CASchools)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In addition, we would like to know how the data set looks like, for example what kind of variables it contains. We do this by invoking the command <code>head</code> which give the first six lines of the data set:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(CASchools)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  district                          school  county grades students teachers
1    75119              Sunol Glen Unified Alameda  KK-08      195    10.90
2    61499            Manzanita Elementary   Butte  KK-08      240    11.15
3    61549     Thermalito Union Elementary   Butte  KK-08     1550    82.90
4    61457 Golden Feather Union Elementary   Butte  KK-08      243    14.00
5    61523        Palermo Union Elementary   Butte  KK-08     1335    71.50
6    62042         Burrel Union Elementary  Fresno  KK-08      137     6.40
  calworks   lunch computer expenditure    income   english  read  math
1   0.5102  2.0408       67    6384.911 22.690001  0.000000 691.6 690.0
2  15.4167 47.9167      101    5099.381  9.824000  4.583333 660.5 661.9
3  55.0323 76.3226      169    5501.955  8.978000 30.000002 636.3 650.9
4  36.4754 77.0492       85    7101.831  8.978000  0.000000 651.9 643.5
5  33.1086 78.4270      171    5235.988  9.080333 13.857677 641.8 639.9
6  12.3188 86.9565       25    5580.147 10.415000 12.408759 605.7 605.4</code></pre>
</div>
</div>
<p>This provides information about the variables and the names and types of variables. In this case variables are either a float (a real number) or a string (text). Note as well, that this kind of output is cumbersome and ugly and not fit directly for reporting. Later, we will try to make this look better in an automatic way.</p>
<p>The command <code>summary</code> gives descriptive statistics. Suppose that in this case we are only interested in the variable <code>math</code> (average scores for mathematics by district). Then we invoke this by:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(CASchools<span class="sc">$</span>math)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  605.4   639.4   652.5   653.3   665.9   709.5 </code></pre>
</div>
</div>
<p>Note that we invoke the command <code>summary</code> and in its argument is one variable <code>math</code> of the dataframe <code>CASchools</code>. We get access to this variable by the use of the <code>$</code>-sign.</p>
<p>Now we see descriptive statistics for the variable <code>math</code>, containing the mean, the standard deviation, the minimum and maximum, and the first and third quartile of this variable. For this exercise and also for the remainder of this syllabus we are actually interested in two variables that are not in the data set, but that we have to compute ourselves; namely, the average test scores of reading and mathematics and the size of the classes (or the student-teacher ratio). We do so as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute new variable STR and append it to CASchools dataframe</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>CASchools<span class="sc">$</span>str <span class="ot">&lt;-</span> CASchools<span class="sc">$</span>students <span class="sc">/</span> CASchools<span class="sc">$</span>teachers </span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># compute new variable TestScore and append it to CASchools dataframe</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>CASchools<span class="sc">$</span>testscr <span class="ot">&lt;-</span> (CASchools<span class="sc">$</span>read <span class="sc">+</span> CASchools<span class="sc">$</span>math) <span class="sc">/</span> <span class="dv">2</span>  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="page-columns page-full"><p>Here, the <code>&lt;-</code> symbol again means you are creating something new on the left hand side of the symbol (in this case a variable in the dataframe <code>CASchools</code>, but in general you always make a new <em>object</em>).</p><div class="no-row-height column-margin column-container"><span class="margin-aside"><code>R</code> is a so-called object-oriented language and (almost) everything is an object including dataframes and variables.</span></div></div>
<p>For a first insight in the relation between class size and class performance we might want to draw a so-called scatter plot. These types of plots relate the values of two variables in a two-dimensional way by giving the values as coordinates. The following syntax will do so.[Note that the first ]</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(CASchools<span class="sc">$</span>str , CASchools<span class="sc">$</span>testscr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-scattercaschool" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scattercaschool-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="linear_regression_files/figure-html/fig-scattercaschool-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scattercaschool-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.1: The relation between average number of pupils in a class room and average test scores in a scatter-plot
</figcaption>
</figure>
</div>
</div>
</div>
<p>This “cloud” of dots does not yield a clearly visible relation between class performance and class size. However, this can be deceptive. Often it is difficult to discern clear relations from raw data only. Therefore we need to resort to numerical evidence.</p>
</section>
<section id="sec-numevidence" class="level3 page-columns page-full" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="sec-numevidence"><span class="header-section-number">2.2.2</span> Numerical evidence</h3>
<p>To assess whether there is a relation between class performance and class size as displayed in <a href="#fig-scattercaschool" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> we need numerical or statistical evidence. Before we start to engage in regression analysis, we first perform a rather simple analysis, but the underlying mechanisms are identical to that of regression analysis. We first create two groups: namely, districts with “small” (number of students per teacher is below 20 or STR <span class="math inline">\(&lt;\)</span> 20) and “large” (number of students per teacher is equal or above 20 or STR <span class="math inline">\(\geq\)</span> 20) class sizes. Then we can adopt three relatively straightforward strategies here:</p>
<ol type="1">
<li>Estimation
<ul>
<li>Here, we compare the average test scores in districts with low student-teacher ratios to those with high student-teacher ratios. So, we basically try to assess whether <strong>average</strong> behaviour is different.</li>
</ul></li>
<li>Hypothesis testing
<ul>
<li>Now, we aim to <strong>test</strong> the “null” hypothesis that the mean test scores in the two types of districts are the same, against the “alternative” hypothesis that they differ.</li>
</ul></li>
<li>Confidence intervals
<ul>
<li>This strategy estimates an interval for the <strong>difference</strong> in the mean test scores, so small versus large student-teacher ratio districts.</li>
</ul></li>
</ol>
<p>In <code>R</code> we can make a start with this data analysis by executing the following two commands:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>CASchools<span class="sc">$</span>large <span class="ot">&lt;-</span> CASchools<span class="sc">$</span>str <span class="sc">&gt;=</span> <span class="dv">20</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>CASchools <span class="sc">%&gt;%</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(large) <span class="sc">%&gt;%</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarise</span>(</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">mean_testscr =</span> <span class="fu">mean</span>(testscr), </span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">sd_testscr =</span> <span class="fu">sd</span>(testscr), </span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">obs =</span> <span class="fu">n</span>()</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 4
  large mean_testscr sd_testscr   obs
  &lt;lgl&gt;        &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;
1 FALSE         657.       19.4   239
2 TRUE          650.       17.9   181</code></pre>
</div>
</div>
<div class="page-columns page-full"><p>We now invoke a second library (a very handy one, called <code>dplyr</code> to create a new dataframe consisting of statistics of our <code>CASchools</code> dataframe. The first command <em>generates</em> a new variable called <code>large</code> and denotes an indicator being 0 (of FALSE) if STR <span class="math inline">\(&lt; 20\)</span> and 1 (or TRUE) if STR <span class="math inline">\(\geq 20\)</span>. The second command summarizes the testscore variable again, but now only gives the mean, standard deviation and the number of observations and does this by each value of the new variable <code>large</code> (the <code>group_by</code> command). Of course, this output is rather ugly and it is better to make a nice table such as <a href="#tbl-smalllarge" class="quarto-xref">Table&nbsp;<span>2.1</span></a>).</p><div class="no-row-height column-margin column-container"><span class="margin-aside">That is, handy in R. This is where programs as <code>STATA</code> would be easier out of the box for these simple tasks. However, <code>dplyr</code> is incredibly powerful and its functionality can be easily extended to all sorts of data managements tasks, making it incredibly powerful.</span></div></div>
<div class="cell">
<div id="tbl-smalllarge" class="cell quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-smalllarge-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2.1: Descriptive statistics of small and large classes
</figcaption>
<div aria-describedby="tbl-smalllarge-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;">Class size</th>
<th style="text-align: left;">Average score</th>
<th style="text-align: left;">Standard deviation</th>
<th style="text-align: left;">Observations</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Small</td>
<td style="text-align: left;">657.2</td>
<td style="text-align: left;">19.4</td>
<td style="text-align: left;">239</td>
</tr>
<tr class="even">
<td style="text-align: left;">Large</td>
<td style="text-align: left;">650.1</td>
<td style="text-align: left;">17.9</td>
<td style="text-align: left;">181</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>Now, for all three strategies (estimation, testing, confidence intervals) we want to know something about the difference—usually denoted as <span class="math inline">\(\Delta\)</span>. Or, specifically:</p>
<ol type="1">
<li>For estimation: determine the <span class="math inline">\(\Delta\)</span> or the difference between group means</li>
<li>For hypothesis testing: can we <em>reject</em> the null-hypothesis that the difference is zero, or<span class="math inline">\(\Delta = 0\)</span></li>
<li>For confidence intervals: can we construct a confidence interval for <span class="math inline">\(\Delta\)</span></li>
</ol>
<section id="estimation" class="level4" data-number="2.2.2.1">
<h4 data-number="2.2.2.1" class="anchored" data-anchor-id="estimation"><span class="header-section-number">2.2.2.1</span> Estimation</h4>
<p>In his case the concept of estimation (that is to determine the difference between the two groups’ average scores) is rather straightforward as we need to calculate the <em>difference</em> between the mean test scores within each group, or:</p>
<p><span class="math display">\[\begin{align}
\bar{Y}_{small} - \bar{Y}_{large} &amp;= \frac{1}{n_{small}} \sum_{i=1}^{n_{small}}Y_i - \frac{1}{n_{large}} \sum_{i=1}^{n_{large}} Y_i \notag \\
&amp;= 657.2-650.1 \notag \\
&amp;=7.2
\label{eq:estimationlarge}
\end{align}\]</span></p>
<p>This basically means subtracting the average scores of <a href="#tbl-smalllarge" class="quarto-xref">Table&nbsp;<span>2.1</span></a> (later we see how to do this automatically in <code>R</code>). Now, the difference—<span class="math inline">\(\Delta\)</span>—equals 7.2. We then have to ask ourselves whether this is a large difference in a real-world sense. Note that, from <a href="#fig-scattercaschool" class="quarto-xref">Figure&nbsp;<span>2.1</span></a>, test scores seem to range from 600 to 800 and do not really have a direct meaning for us. A useful trick then is to look at the standard deviation (note that if things are normally distributed, 95% of all probability mass is within the range mean plus or minus two times the standard deviation). In this case, the difference is about <span class="math inline">\(1/3\)</span> of the standard deviation. A different way of looking at this is looking at the percentiles of test scores. In <code>R</code> this looks like:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>quantiles <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.10</span>, <span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">0.9</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(CASchools<span class="sc">$</span>testscr, quantiles)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     10%      25%      50%      75%      90% 
630.3950 640.0500 654.4500 666.6625 678.8600 </code></pre>
</div>
</div>
<p>where the command <code>quantile</code> asks for a tabulation of certain statistics and gives the <span class="math inline">\(x\)</span>-th percentile of that statistic. Now note that between the 50th and 75th percentile there is only 12 points. So given this information, the difference of <span class="math inline">\(7.4\)</span> is rather sizable. But whether this difference is big enough to be important for school reform discussions, for parents, or for a school committee is a question we cannot answer with this analysis.</p>
</section>
<section id="hypothesis-testing" class="level4" data-number="2.2.2.2">
<h4 data-number="2.2.2.2" class="anchored" data-anchor-id="hypothesis-testing"><span class="header-section-number">2.2.2.2</span> Hypothesis testing</h4>
<p>An alternative is to test the null-hypothesis that the difference <span class="math inline">\(\Delta = 0\)</span>. For that we need a so-called difference-in-means test and compute the corresponding <span class="math inline">\(t\)</span>-statistic,<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> <span class="math display">\[\begin{equation}
t = \frac{\bar{Y}_s - \bar{Y}_l}{\sqrt{\frac{s^2_s}{n_s} +\frac{s^2_l}{n_l} }} = \frac{\bar{Y}_s - \bar{Y}_l}{SE(\bar{Y}_s - \bar{Y}_l)}
\label{eq:testinglarge}
\end{equation}\]</span> where <span class="math inline">\(SE(\bar{Y}_s - \bar{Y}_l)\)</span> is the <em>standard error</em> of <span class="math inline">\((\bar{Y}_s - \bar{Y}_l)\)</span>, the subscripts <span class="math inline">\(s\)</span> and <span class="math inline">\(l\)</span> refer to “small” and “large” STR districts, and <span class="math inline">\(s_s^2 = \frac{1}{n_{small}}\sum_{i=1}^{n_s}(Y_i - \bar{Y}_s)^2\)</span></p>
<p>We can compute this difference-of-means <span class="math inline">\(t\)</span>-statistic by filling this in with the numbers of <a href="#tbl-smalllarge" class="quarto-xref">Table&nbsp;<span>2.1</span></a>: <span class="math display">\[\begin{equation}
t = \frac{\bar{Y}_s - \bar{Y}_l}{\sqrt{\frac{s^2_s}{n_s} +\frac{s^2_l}{n_l} }}  = \frac{657.2 - 650.1}{\sqrt{\frac{19.4^2}{238} +\frac{17.9^2}{182} }} = \frac{7.2}{1.83} = 3.92
\end{equation}\]</span></p>
<p>But then what? Well, recall that we <strong>reject</strong> a null-hypothesis when the critical value is below a certain threshold (usually 5%). In this case that is equivalent with stating that <span class="math inline">\(|t|&gt;1.96\)</span>. So, we reject (at the 5% significance level) the null hypothesis that the two means are the same. We will come back to this procedure in <a href="#sec-unitesting" class="quarto-xref"><span>Section 2.3.2.2</span></a>.</p>
</section>
<section id="confidence-interval" class="level4" data-number="2.2.2.3">
<h4 data-number="2.2.2.3" class="anchored" data-anchor-id="confidence-interval"><span class="header-section-number">2.2.2.3</span> Confidence interval</h4>
<p>Finally, we can construct a 95% confidence interval for the difference between the means, which is: <span class="math display">\[\begin{equation}
(\bar{Y}_s - \bar{Y}_l)\pm 1.96 \times SE(\bar{Y}_s - \bar{Y}_l) = 7.2 \pm 1.96 \times 1.83 = (3.6, 10.8)
\label{eq:cilarge}
\end{equation}\]</span> So, what does this mean again. Well, two things. First, the 95% confidence interval for <span class="math inline">\(\Delta\)</span> doesn’t include 0 and, second, the hypothesis that <span class="math inline">\(\Delta = 0\)</span> is rejected at the 5% level. We will come back to confidence intervals as well, but for now a confidence interval can be seen as an interval of numbers that will not be rejected as null-hypothesis.</p>
</section>
</section>
<section id="sec-smart" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="sec-smart"><span class="header-section-number">2.2.3</span> Always be smart (and a bit lazy)</h3>
<p>So, why give this rather simple procedure so much attention. That is because all “classical” statistics are centered around these three elements and statistical computer output will always give, at least, these three. And they are as well very much related with each other. Once you know two of them, you know the third one as well.</p>
<p>Now, although the procedure is rather straightforward, it is also a bit cumbersome and prone to errors. Therefore, it is much easier to let <code>R</code> do it:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(testscr <span class="sc">~</span> large, <span class="at">data =</span> CASchools)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Welch Two Sample t-test

data:  testscr by large
t = 3.9268, df = 402.34, p-value = 0.0001013
alternative hypothesis: true difference in means between group FALSE and group TRUE is not equal to 0
95 percent confidence interval:
  3.580186 10.758685
sample estimates:
mean in group FALSE  mean in group TRUE 
           657.2462            650.0768 </code></pre>
</div>
</div>
<p>So, in this case we want to assess the difference in test score by groups (being small and large classes). Note, however that the difference in means, <span class="math inline">\(t\)</span>-statistic and thus the confidence intervals are similar as in, e.g., equation <span class="math inline">\(\ref{eq:cilarge}\)</span>.</p>
<p>Now try to find out for yourself that this output gives you the estimation of <span class="math inline">\(\Delta\)</span> of equation <span class="math inline">\(\ref{eq:estimationlarge}\)</span>, the <span class="math inline">\(t\)</span>-value and corresponding test outcome of equation <span class="math inline">\(\ref{eq:testinglarge}\)</span> where the corresponding confidence intervals of equation <span class="math inline">\(\ref{eq:cilarge}\)</span> can be readily calculated.</p>
</section>
</section>
<section id="sec-uniregress" class="level2 page-columns page-full" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="sec-uniregress"><span class="header-section-number">2.3</span> Univariate regression</h2>
<p>The three strategies we adopted in <a href="#sec-numevidence" class="quarto-xref"><span>Section 2.2.2</span></a> for assessing the difference between groups directly translate to the case of regression analysis. Here we also look at estimation, hypothesis testing and confidence intervals. But before that we first look at the origin of the name regression in <a href="#sec-genesis" class="quarto-xref"><span>Section 2.3.1</span></a>.</p>
<section id="sec-genesis" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="sec-genesis"><span class="header-section-number">2.3.1</span> Genesis: <em>regression towards the mean</em></h3>
<p>The name regression seems to have a negative connotation, as progress is in general seen as good and regression as bad. And actually this is true as the name regression was deliberately given as to describe a negative process: in full <em>regression towards the mean</em>. The concept of regression was actually coined by Sir Francis Galton together with other statistical terms, such as correlation and deviation <span class="citation" data-cites="senn2011francis">(<a href="references.html#ref-senn2011francis" role="doc-biblioref">Senn 2011</a>)</span>. Galton was a notorious statistician who measured everything and else, including the length of french bread and the size of human skulls.</p>
<p>in 1886, Galton started to research the height of adult children with the height of their parents <span class="citation" data-cites="galton1886regression">(<a href="references.html#ref-galton1886regression" role="doc-biblioref">Galton 1886</a>)</span>. The original data can be seen in the scatterplot in <a href="#fig-galton2" class="quarto-xref">Figure&nbsp;<span>2.2</span></a>. What Galton expected was that the relation between the height of children and that of their parents was a one-to-one relation. On average children should receive the same height of their parents. So, in fact he expected a <span class="math inline">\(45^{\circ}\)</span> line—the red line; a line with slope equal to 1.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-galton2" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-galton2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./figures/Galton2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-galton2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.2: Relation between the heigh fathers and the height of children
</figcaption>
</figure>
</div>
</div>
</div>
<p>However, he found consistently the blue line, a line with positive slope but lower than 1 (the blue line in <a href="#fig-galton1" class="quarto-xref">Figure&nbsp;<span>2.3</span></a>). That entails that, <em>on average</em> tall parents get tall children but not as tall as themselves. Of course, this goes as well the other way. Short parents get short children but not as short as themselves.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-galton1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-galton1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./figures/Galton1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-galton1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.3: Relation heigh fathers and height children
</figcaption>
</figure>
</div>
</div>
</div>
<p>Galton coined this process <em>regression towards the mean</em>.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> In the end we would all converge towards the mean and all look the same. For the Victorian Sir Frances Galton and his contemporaries in an age where social and income classes were highly separated this was truly a horror. Especially, because his cousin was Charles Darwin who actually claimed that species <em>diverged</em>. Of course, in Galton reasoning there is a mistake as this only models genetic influence and not <em>accidental</em> differences not influenced by genetics. Note as well that this analysis says something about the average, but not about individual differences.</p>
<p>This regression towards the mean is now seen as a very important characteristic of regression models, and you can easily be fooled by it. It is now stated as:</p>
<blockquote class="blockquote">
<p><span class="math inline">\(\ldots\)</span> a concept that refers to the fact that if one sample of a random variable is extreme, the next sampling of the same random variable is likely to be closer to its mean</p>
</blockquote>
<p>For instance, suppose that everything went really well for a course and you got a 9 for an examination. That does not mean that the next time you will do equally well (you will still do well, but not that well). Or, your favorite football club does extremely well in a particular year (Leicester City FC comes to mind who became premier league champion in 2016). That does not mean that the next year it will do equally well, and so forth and so on.</p>
</section>
<section id="regression-with-one-regressor" class="level3 page-columns page-full" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="regression-with-one-regressor"><span class="header-section-number">2.3.2</span> Regression with one regressor</h3>
<p>So, linear regression allows us to <em>estimate</em>, and make <em>inferences</em> about, <em>population</em> slope coefficients. Inference means drawing conclusions and population refers to the fact that we do not want to say something about our sample, but instead about the whole population. Ultimately our aim is to estimate the <strong>causal</strong> effect on <span class="math inline">\(Y\)</span> of a unit change in <span class="math inline">\(X\)</span>—but for now, just think of the problem of fitting a straight line to data on two variables, <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>.</p>
<p>Similar to Subsection <a href="#sec-numevidence" class="quarto-xref"><span>Section 2.2.2</span></a>) we have three strategies to make inferences:</p>
<ul>
<li>We estimation the relation:
<ul>
<li>This now boils down to the question how we should draw a line through the data to estimate the (population) slope using Ordinary Least Squares (OLS—a specific and most common type of regression analysis)</li>
<li>And then we have to assess the advantages and disadvantages of OLS</li>
</ul></li>
<li>We could refer to hypothesis testing:
<ul>
<li>Very often this comes down to testing where the slope is zero. Namely, if the slope is zero, then the data does not show a relation between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>.</li>
</ul></li>
<li>Using confidence intervals:
<ul>
<li>This is related to constructing a confidence interval for the slope</li>
</ul></li>
</ul>
<p>Before we look into this we first need some clarification on notation. As mentioned above, we would like to know the population regression line:</p>
<p><span class="math display">\[\begin{equation}
testscr = \beta_0 + \beta_1 STR,
\end{equation}\]</span> where <span class="math display">\[\begin{eqnarray}
    \beta_1&amp; =&amp; \text{slope of population regression line} \notag \\
    &amp;=&amp;   \frac{\Delta Testscore}{\Delta STR} \notag \\
    &amp;=&amp; \text{change in test score for a \textbf{unit} change in STR}
\end{eqnarray}\]</span> Note the definition here of <span class="math inline">\(\beta_1\)</span>. It gives the <strong>marginal effect</strong> of a change in <span class="math inline">\(STR\)</span> on <span class="math inline">\(testscr\)</span>. So the interpretation of the parameter <span class="math inline">\(\beta_1\)</span> is very straightforward. However, we do not know the population value of <span class="math inline">\(\beta_1\)</span> and we therefore have to estimate it using data.</p>
<p>In general, the population linear regression <em>model</em> is different as we add element <span class="math inline">\(u_1\)</span>. <span class="math display">\[\begin{equation}
    Y_i = \beta_0 + \beta_1 X_i + u_i, \qquad i\ldots n
    \label{eq:ols}
\end{equation}\]</span> Now, <span class="math inline">\(X\)</span> denotes the independent variable or regressor, <span class="math inline">\(Y\)</span> the dependent variable, <span class="math inline">\(\beta_0\)</span> the intercept, <span class="math inline">\(\beta_1\)</span> the slope, and <span class="math inline">\(u_i\)</span> the regression error. The regression error consists of omitted factors, or possibly measurement error in the measurement of <span class="math inline">\(Y\)</span>. In general, these omitted factors are other factors that influence <span class="math inline">\(Y\)</span>, other than the variable <span class="math inline">\(X\)</span>.</p>
<section id="estimating-with-ols" class="level4 page-columns page-full" data-number="2.3.2.1">
<h4 data-number="2.3.2.1" class="anchored" data-anchor-id="estimating-with-ols"><span class="header-section-number">2.3.2.1</span> Estimating with OLS</h4>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-unire" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-unire-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./figures/Lecture1_sheet8.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-unire-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.4: Drawing a straight line through data in a scatterplot
</figcaption>
</figure>
</div>
</div>
</div>
<p>To estimate the population linear regression model we apply the ordinary least squares estimator. Again, as <a href="#fig-unire" class="quarto-xref">Figure&nbsp;<span>2.4</span></a> shows as well, a linear regression line is a straight line through points in a scatterplot. Actually, we want to draw that line such that the distance of all points to that line is minimized. See that in <a href="#fig-unire" class="quarto-xref">Figure&nbsp;<span>2.4</span></a> the distances between the points and the line are given by the <span class="math inline">\(u_i\)</span>’s, the regression errors. So, if we somehow can minimize all <span class="math inline">\(u_i\)</span>’s we are fine. But those distances could be both positive and negative and they might cancel each other out. Therefore, we first square the regression errors and then minimize (hence the name: ordinary least <em>squares</em>). Also, see from Eq. <span class="math inline">\(\ref{eq:ols}\)</span> that:</p>
<p><span class="math display">\[\begin{equation}
u_i = Y_i - (\beta_0 + \beta_1 X_i) \longleftrightarrow (u_i)^2 = \left[Y_i - (\beta_0 + \beta_1 X_i) \right]^2
\end{equation}\]</span></p>
<p>But how can we estimate <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> from data? For that we will focus on the least squares (ordinary least squares or OLS) estimator of the unknown parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, which solves, <span class="math display">\[\begin{equation}
    \min_{b_0,b_1} \sum^n_{i=1} \left[Y_i - (b_0 + b_1 X_i) \right]^2
\end{equation}\]</span></p>
<p>In fact, the OLS estimators of the slope <span class="math inline">\(\beta\)</span><span class="math inline">\(_1\)</span> and the intercept <span class="math inline">\(\beta\)</span><span class="math inline">\(_0\)</span> are:<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p><span class="math display">\[\begin{eqnarray}
    \hat{\beta}_1 &amp;=&amp; \frac{\sum^n_{i=1}(X_i - \overline{X})(Y_i - \overline{Y})}{\sum^n_{i=1}(X_i - \overline{X})^2} = \frac{s_{XY}}{s^2_X}\\
    \hat{\beta}_0 &amp;=&amp; \overline{Y} - \hat{\beta}_1\overline{X}
\end{eqnarray}\]</span></p>
<p>Although you do <strong>not</strong> need to learn these formula’s by heart some insightful comments can be retrieved from them. First, if a parameter is estimated then it gets a hat symbol on its top. Second, the optimal <span class="math inline">\(\hat{\beta}_1\)</span> is equal to <span class="math inline">\(\frac{s_{XY}}{s^2_X}\)</span> and this is the sampling covariance between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> divided by the sampling variance of <span class="math inline">\(X\)</span>. This is not a correlation as the units still depend on <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> and therefore the slope can be larger than <span class="math inline">\(1\)</span> or smaller than <span class="math inline">\(-1\)</span>, but it does say something about the relation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Third, the constant is governed by the estimated parameter <span class="math inline">\(\hat{\beta}_0\)</span>.</p>
<p>From here we can predict the values <span class="math inline">\(\hat{Y}_i\)</span> and residuals <span class="math inline">\(\hat{u}_i\)</span> as they are: <span class="math display">\[\begin{eqnarray}
    \hat{Y}_i &amp;=&amp; \hat{\beta}_0 + \hat{\beta}_1 X_i, \qquad i = 1, \ldots, n \notag\\
    \hat{u}_i &amp;=&amp; Y_i - \hat{Y}_i, \qquad i = 1, \ldots, n
\end{eqnarray}\]</span></p>
<p>When we apply this to our data cloud in <a href="#fig-scattercaschool" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> then we get the following optimal population regression line:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-cloud" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cloud-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./figures/Lecture1_sheet13.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cloud-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.5: Scatterplot and estimated regression line
</figcaption>
</figure>
</div>
</div>
</div>
<p>where the estimated slope equals <span class="math inline">\(\hat{\beta}_1 = -2.28\)</span>, the estimated intercept equals <span class="math inline">\(\hat{\beta}_0 = 698.9\)</span> and the total population regression line can be written as: <span class="math inline">\(\widehat{TestScore} = 698.9 - 2.28 \times STR\)</span>. So, how to interpret the estimated slope and intercept now? First, the slope entails that districts with one more student per teacher on average have test scores that are 2.28 points lower (that is, <span class="math inline">\(\frac{\Delta TestScore}{\Delta STR} =-2.28\)</span>). Secondly, the intercept (taken literally) means that, according to this estimated line, districts with zero students per teacher would have a (predicted) test score of 698.9. Now, this does not make any sense—it actually extrapolates the line outside the range of the data. In this case we can say that the intercept is not economically meaningful.</p>
<p>Now, how to fill in predictions? One of the districts in the data set is Antelope (CA) for which <span class="math inline">\(STR = 19.33\)</span> and <span class="math inline">\(TestScore = 657.8\)</span> Then the predicted value for the testscore is <span class="math inline">\(\hat{Y}_{Antelope}= 698.9 - 2.28 \times 19.33 = 654.8\)</span> and the resulting residual is <span class="math inline">\(\hat{u}_{Antelope} = 657.8 - 654.8 = 3.0\)</span></p>
<div class="page-columns page-full"><p>In <code>R</code> both the constant and the slope can be easily retrieved by:</p><div class="no-row-height column-margin column-container"><span class="margin-aside">The command <code>lm</code> stands for linear model. Note as well how the formula is specified. First, the dependent variable, then a <code>~</code> sign and then the independent variable. Finally, we have to specify which dataframe to use; namely, <code>R</code> can have several dataframes in its memory.</span></div></div>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>model_1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(testscr <span class="sc">~</span> str, <span class="at">data =</span> CASchools)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = testscr ~ str, data = CASchools)

Residuals:
    Min      1Q  Median      3Q     Max 
-47.727 -14.251   0.483  12.822  48.540 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 698.9329     9.4675  73.825  &lt; 2e-16 ***
str          -2.2798     0.4798  -4.751 2.78e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 18.58 on 418 degrees of freedom
Multiple R-squared:  0.05124,   Adjusted R-squared:  0.04897 
F-statistic: 22.58 on 1 and 418 DF,  p-value: 2.783e-06</code></pre>
</div>
</div>
<p>We will discuss the rest of this output later.</p>
</section>
<section id="sec-unitesting" class="level4" data-number="2.3.2.2">
<h4 data-number="2.3.2.2" class="anchored" data-anchor-id="sec-unitesting"><span class="header-section-number">2.3.2.2</span> Hypothesis testing</h4>
<p>We can assess the importance of the line as well with hypothesis testing. Again, recall that in in applied econometrics we will only <strong>reject</strong> the <strong>null</strong>-hypothesis, we do not accept an hypothesis based upon one statistical test only. So, we aim to test <span class="math inline">\(H_0: E(Y) = \mu_{Y,0}\)</span> vs.&nbsp;<span class="math inline">\(H_1: E(Y) \neq \mu_{Y,0}\)</span>, where <span class="math inline">\(\mu_{Y,0}\)</span> is some pre-specified quantity that we are interested in. Typically <span class="math inline">\(\mu_{Y,0} = 0\)</span> as this denotes no relation, but sometimes you could be interested in, e.g., whether <span class="math inline">\(\mu_{Y,0} = 1\)</span> when testing elasticities. Or you could be interested in other quantities.</p>
<p>Testing statistical hypotheses is often very confusing, because of two things. First, you actually test whether the data you have corresponds with the null-hypothesis. Or, in other words:</p>
<blockquote class="blockquote">
<p>What is the probability that your data (<span class="math inline">\(D\)</span>) might be right <em>given</em> the null-hypothesis (<span class="math inline">\(H_0\)</span>): <span class="math inline">\(\Pr(D|H_0)\)</span></p>
</blockquote>
<p>And that is a strange concept. You first imagine a world <span class="math inline">\(H_0\)</span> with the data that it <em>should</em> provide and then test that imaginary world.</p>
<p>Secondly, there is the notation that often works confusing. First, we have the <span class="math inline">\(p\)</span>-value which equals the probability of drawing a statistic (e.g., <span class="math inline">\(\bar{Y}\)</span>) <em>at least as adverse</em> to the null (that is: your imaginary world) as the value actually computed with your data, <strong>assuming</strong> again that the null-hypothesis is true—again, your imaginary world. Secondly, there is the significance level of a test which is a <em>pre-specified</em> probability of incorrectly rejecting the null, when the null is actually true.</p>
<p>Now, suppose that you want to calculate the <span class="math inline">\(p\)</span>-value based on an estimated coefficient <span class="math inline">\(\hat{\beta}_1\)</span>, then you construct the following test: <span class="math display">\[\begin{equation}
p\text{-value} = \Pr_{H_0}[|\hat{\beta}_1 - \beta_{1,0}| &gt; |\hat{\beta}_1^{act} - \beta_{1,0}|
\end{equation}\]</span> where <span class="math inline">\(\hat{\beta}_1^{act}\)</span> is the value of <span class="math inline">\(\hat{\beta}_1\)</span> actually observed, and <span class="math inline">\(\beta_{1,0}\)</span> is the value of <span class="math inline">\(\beta_1\)</span> under the null-hypothesis (e.g., <span class="math inline">\(\beta_{1,0} = 0\)</span>). Now, this is confusing, but in words it states that if you belief the null-hypothesis, what is then the <em>probability</em> that the estimated value is <span class="math inline">\(\hat{\beta}_1^{act}\)</span> or even more adverse to the value of the null hypothesis (in other words even more extreme values).</p>
<p>To test the null hypothesis <span class="math inline">\(H_0\)</span> we follow three steps. First, we need to compute the <strong>standard error</strong> of <span class="math inline">\(\hat{\beta_1}\)</span>, which is an estimator of <span class="math inline">\(\sigma_{\hat{\beta_1}}\)</span>. Using an ordinary least squares estimator, standard errors for coefficients are given by:</p>
<p><span class="math display">\[\begin{equation}
\sigma_{\hat{\beta_1}} = \sqrt{\frac{1}{n} \frac{\frac{1}{n-2} \sum_{i=1}^n (X_i - \bar{X})^2 u_i^2}{\left[\frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})^2 \right]^2}},
\label{eq:olsse}
\end{equation}\]</span> which is a rather daunting expression.</p>
<p>Second, we need to compute the <span class="math inline">\(t\)</span>-statistic: <span class="math display">\[\begin{equation}
t = \frac{\hat{\beta}_1 - \beta_{1,0}}{\sigma_{\hat{\beta_1}} }
\label{eq:olst}
\end{equation}\]</span></p>
<p>Finally, we need to calculate the <span class="math inline">\(p\)</span>-value. To do so, we need to know the sampling distribution of <span class="math inline">\(\hat{\beta}_1\)</span>, which we know is complicated if <span class="math inline">\(n\)</span> is small, but typically you have enough observations to invoke the <em>Central Limit Theorem</em>. So, if <span class="math inline">\(n\)</span> is large, you can use the normal approximation (CLT) as follows <span class="math display">\[\begin{eqnarray}
                        p\text{-value}&amp; = &amp;   \Pr_{H_0}\left[\left|\hat{\beta}_1 - \beta_{1,0}\right| &gt; \left|\hat{\beta}_1^{act} - \beta_{1,0}\right|\right] \notag\\
            &amp; = &amp;   \Pr_{H_0}\left[\left|\frac{\hat{\beta}_1 - \beta_{1,0}}{\sigma_{\hat{\beta_1}} }\right| &gt; \left|\frac{\hat{\beta}_1 ^{act} - \beta_{1,0}}{\sigma_{\hat{\beta_1}} }\right|\right] \notag \\
            &amp; = &amp;   \Pr_{H_0}[|t| &gt; |t^{act}|] \notag \\
                        &amp;\simeq&amp; \text{probability under left + right } N(0,1) \text{ tails}
\end{eqnarray}\]</span> where <span class="math inline">\(\sigma_{\hat{\beta_1}}\)</span> again equals the standard error of <span class="math inline">\(\hat{\beta}_1\)</span>,</p>
<p>So, if you know <span class="math inline">\(\hat{\beta}_1\)</span> and <span class="math inline">\(\sigma_{\hat{\beta}_1}\)</span> you can calculate this. However, computers are much faster, in doing to. For example, suppose we want to test whether <span class="math inline">\(\beta_{1,0} = 0\)</span> using the regression output displayed above which gives <span class="math inline">\(\hat{\beta}_1 = -2.28\)</span> and <span class="math inline">\(\sigma_{\hat{\beta}_1} = 0.52\)</span>. That is step 1. Note that <code>R</code> already calculated the standard error of Eq. <span class="math inline">\(\ref{eq:olsse}\)</span>. For the next step we need to compute the <span class="math inline">\(t\)</span>-statistic, which is:</p>
<p><span class="math display">\[\begin{equation}
t^{act} = \frac{2.28 - \beta_{1,0}}{0.52} = \frac{2.28 - 0}{0.52} = -4.39.
\label{eq:olstemp}
\end{equation}\]</span></p>
<p>then the <span class="math inline">\(p\)</span>-value can be seen from <a href="#fig-pvalues" class="quarto-xref">Figure&nbsp;<span>2.6</span></a>:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-pvalues" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pvalues-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./figures/lecture_sheet9.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pvalues-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.6: Calculating the <span class="math inline">\(p\)</span>-value of a two-sided test when <span class="math inline">\(t^{act} = -4.38\)</span>
</figcaption>
</figure>
</div>
</div>
</div>
<p>That is, for large <span class="math inline">\(n\)</span> (and typically we have that), the <span class="math inline">\(p\)</span>-value is the probability that a <span class="math inline">\(N(0,1)\)</span> random variable falls outside <span class="math inline">\(|\hat{\beta}_1^{act} - \beta_{1,0})/\sigma_{\hat{\beta}_1} | = |t|\)</span>. That is the blue areas under the normal distribution and they entail a probability <em>mass</em>. Now, if both surfaces on the sides are not larger than 2.5%, then we can reject the null-hypothesis against a 5% significance level. Now, the computer output above gives a <span class="math inline">\(p\)</span>-value of <span class="math inline">\(0.000\)</span>, which is a bit strange. The <span class="math inline">\(p\)</span>-value is actually not zero, but a very small number and definitely smaller than <span class="math inline">\(0.05\)</span>, so we can <em>reject</em> the null-hypothesis being <span class="math inline">\(\beta_{1,0} = 0\)</span> at a 5% significance level (and at a 1% and 0.1% significance level as well). Now, if the <span class="math inline">\(t\)</span>-statistic is exactly 1.96 in absolute value, then the <span class="math inline">\(p\)</span>-value is 0.05. So, to repeat the steps, but now using computer output for testing the hypothesis that <span class="math inline">\(\beta_1 = \beta_{1,0}\)</span></p>
<ol type="1">
<li>Get the standard error from computer output</li>
<li>Compute the <span class="math inline">\(t^{act}\)</span>-statistics as in Eq. <span class="math inline">\(\ref{eq:olst}\)</span></li>
<li>Get the corresponding <span class="math inline">\(p\)</span>-value. Or, reject the null-hypothesis at the 5% significance level if <span class="math inline">\(|t^{act}| &gt; 1.96\)</span>.</li>
</ol>
<p>Now there is a link between the <span class="math inline">\(p\)</span>-value and the significance level. The significance level is pre-specified. For example, if the pre-specified significance level is 5%, then you reject the null hypothesis if <span class="math inline">\(|t| \geq 1.96\)</span> or equivalently, you reject if <span class="math inline">\(p \leq 0.05\)</span>. The <span class="math inline">\(p\)</span>-value is sometimes called the marginal significance level. Often, it is better to communicate the <span class="math inline">\(p\)</span>-value than simply whether a test rejects or not—the <span class="math inline">\(p\)</span>-value contains more information than the “yes/no” statement about whether the test rejects.</p>
<p>But recently there has been some debate about using <span class="math inline">\(p\)</span>-values <span class="citation" data-cites="amrhein2019scientists">(<a href="references.html#ref-amrhein2019scientists" role="doc-biblioref">Amrhein, Greenland, and McShane 2019</a>)</span>. Why should you use a 5% significance level, what is so special about that number? Is it not better just to report coefficients and standard errors? <a href="#fig-significance" class="quarto-xref">Figure&nbsp;<span>2.7</span></a> shows a figure from the journal Nature and how scientists across all fields nowadays see <span class="math inline">\(p\)</span>-values and statistical significance. This is not to say that statistical testing does not matter, but more the reporting of that statistical testing. First of all, <span class="math inline">\(p\)</span>-values in themselves do not contain that much information. In the regression output of above the reported <span class="math inline">\(p\)</span>-values are being equal to 0.000 which is not informative. Secondly, the cut-off point of 5% is a bit harsh and could lead to publications being published only with <span class="math inline">\(p\)</span>-values just below 0.05, leading to what is called publication bias.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-significance" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-significance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./figures/significance.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-significance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.7: Critical review on the (mis)use of statistical significance
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="confidence-intervals" class="level4" data-number="2.3.2.3">
<h4 data-number="2.3.2.3" class="anchored" data-anchor-id="confidence-intervals"><span class="header-section-number">2.3.2.3</span> Confidence intervals</h4>
<p>The exact definition of confidence intervals is a bit tricky. Namely, a 95% confidence interval for <span class="math inline">\(\hat{\beta}_1\)</span> is an interval that contains the true value of <span class="math inline">\(\beta_1\)</span> in 95% of repeated samples. That means that a confidence interval does not give a probability (even though we would like to interpret it that way). But you can state that every value within a confidence interval would not be rejected as null-hypothesis, while every value outside the confidence interval would be rejected. Now, if we know both <span class="math inline">\(\hat{\beta}_1\)</span> and <span class="math inline">\(\sigma_{\hat{\beta}_1}\)</span> (again using computer output), then a 95% confidence interval can be very easily constructed. For our regression of output of above this entails</p>
<p><span class="math display">\[\begin{equation}
\hat{\beta}_1 \pm 1.96 \times \sigma_{\hat{\beta}_1} = -2.28 \pm 1.96 \times 0.52 = [-3.30, -1.26].
\label{eq:olsci}
\end{equation}\]</span> So, every value between <span class="math inline">\(-3.30\)</span> and <span class="math inline">\(-1.26\)</span> will <strong>not</strong> be rejected as null-hypothesis, while every value outside that interval will be rejected. Note that confidence intervals are again automatically given by computer output. If one would like a confidence interval against another critical level, say against a 99% critical level, one can use the <code>confint.lm()</code> command.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>model_1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(testscr <span class="sc">~</span> str, <span class="at">data =</span> CASchools)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confint.lm</span>(model_1, <span class="at">level =</span> <span class="fl">0.99</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                 0.5 %     99.5 %
(Intercept) 674.434471 723.431428
str          -3.521425  -1.038191</code></pre>
</div>
</div>
</section>
<section id="sec-dummy" class="level4 page-columns page-full" data-number="2.3.2.4">
<h4 data-number="2.3.2.4" class="anchored" data-anchor-id="sec-dummy"><span class="header-section-number">2.3.2.4</span> Regression with a dummy</h4>
<p>Sometimes a regressor is binary, meaning an indicator or a dichotomous (0/1) variable. Let’s go back again to <a href="#sec-numevidence" class="quarto-xref"><span>Section 2.2.2</span></a>, where we created such a binary variable with small and large class sizes (<span class="math inline">\(X=1\)</span> if class size is small, <span class="math inline">\(X=0\)</span> if not). Other possible examples are gender (<span class="math inline">\(X=1\)</span> if female, <span class="math inline">\(X=0\)</span> if male) or being treated or not (<span class="math inline">\(X=1\)</span> if treated, <span class="math inline">\(X=0\)</span> if not). We refer to these types of variables as being <strong>dummy</strong> variables—and they are very often used in the social sciences.</p>
<p>Now, suppose we have a population regression model that looks like:</p>
<p><span class="math display">\[\begin{equation}
Y_i = \beta_0 + \beta_1 X_i + u_i
\label{eq:olsdummy}
\end{equation}\]</span></p>
<p>Where <span class="math inline">\(Y\)</span> denotes, e.g., test scores, and where <span class="math inline">\(X\)</span>, e.g., denotes a dummy variable for a large class (so, if <span class="math inline">\(STR \geq 20\)</span> then <span class="math inline">\(X_i = 1\)</span>; otherwise <span class="math inline">\(X_i = 0\)</span>), so there is then only two possibilities:</p>
<ol type="1">
<li>For small class size there should hold that <span class="math inline">\(X_i = 0\)</span> yielding that <span class="math inline">\(Y_i = \beta_0 + u_i\)</span>. Namely <span class="math inline">\(\beta_1 \times X_i = \beta_1 \times 0 = 0\)</span>. That means automatically that the expectation of <span class="math inline">\(Y_i\)</span> is the constant, being <span class="math inline">\(\beta_0\)</span>. Another way or writing is that the expectation of model <span class="math inline">\(\ref{eq:olsdummy}\)</span> <em>conditional</em> on the fact that <span class="math inline">\(X_i = 0\)</span> is <span class="math inline">\(\mathbb{E}(Y_i \mid X_i = 0) = \beta_0\)</span>.</li>
<li>For large classes there should hold that <span class="math inline">\(X_i = 1\)</span> yielding that <span class="math inline">\(X_i = 1\)</span>, <span class="math inline">\(Y_i = \beta_0 + \beta_1 + u_i\)</span>. This means that the expectation of model <span class="math inline">\(\ref{eq:olsdummy}\)</span> <em>conditional</em> on the fact that <span class="math inline">\(X_i = 1\)</span> is <span class="math inline">\(\mathbb{E}(Y_i \mid X_i = 1) = \beta_0 + \beta_1\)</span></li>
</ol>
<p>So a regression with a dummy as independent variable gives two different <em>constants</em>, for each group (small/large classes) one. You can interpret this as a level-effect (only the level changes, not the slope as there is none here). The interpretation of <span class="math inline">\(\beta_1\)</span> is in this case rather special and can be denoted as: <span class="math display">\[\begin{equation}
\beta_1 = \mathbb{E}(Y_i \mid X_i = 1) - \mathbb{E}(Y_i \mid X_i = 0),
\end{equation}\]</span> Which is just the population difference in group means.</p>
<p>If we go back to our example with <span class="math inline">\(X_i = 1\)</span> if <span class="math inline">\(STR \geq 20\)</span> and 0 otherwise then we get the following regression output</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>model_2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(testscr <span class="sc">~</span> <span class="fu">factor</span>(large), <span class="at">data =</span> CASchools)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = testscr ~ factor(large), data = CASchools)

Residuals:
    Min      1Q  Median      3Q     Max 
-50.496 -14.029  -0.346  12.884  49.504 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)        657.246      1.212 542.162  &lt; 2e-16 ***
factor(large)TRUE   -7.169      1.847  -3.882  0.00012 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 18.74 on 418 degrees of freedom
Multiple R-squared:  0.0348,    Adjusted R-squared:  0.0325 
F-statistic: 15.07 on 1 and 418 DF,  p-value: 0.0001202</code></pre>
</div>
</div>
<div class="page-columns page-full"><p>Now, note that this is the same output (<span class="math inline">\(\Delta= -7.2\)</span>, <span class="math inline">\(\sigma_\Delta = 1.85\)</span> and <span class="math inline">\(t\)</span>-statistic is <span class="math inline">\(-3.88\)</span>) as when we did the difference in means test in <a href="#sec-smart" class="quarto-xref"><span>Section 2.2.3</span></a> (using the <code>R</code> way). To conclude, this is just another way (and much easier) to do a difference-in-means analysis. And this directly carries over for the situation when we have additional regressors.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">They are not exactly the same though and that is that <code>R</code> for the <span class="math inline">\(t\)</span>-test in <a href="#sec-smart" class="quarto-xref"><span>Section 2.2.3</span></a> corrects for the degrees of freedom, or the number of variables it uses. In large sample they coincide though.</span></div></div>
</section>
</section>
</section>
<section id="sec-lsa" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="sec-lsa"><span class="header-section-number">2.4</span> Least squares assumptions for causal inference</h2>
<p>As stated at the start of <a href="#sec-problem" class="quarto-xref"><span>Section 2.2</span></a> applied econometrics focuses on finding a <strong>causal</strong> effect. But how do you do know that the <span class="math inline">\(\hat{\beta}_1\)</span> you estimate using the population regression model of Eq. <span class="math inline">\(\ref{eq:betacausal}\)</span> is indeed a causal effect. In other words, if you change <span class="math inline">\(X_i\)</span> with one unit, will <span class="math inline">\(Y_i\)</span> then change with <span class="math inline">\(\beta_1\)</span> <strong>in reality</strong>?</p>
<p><span class="math display">\[\begin{equation}
Y_i = \beta_0 + \beta_1 X_i + u_i, \qquad i = 1 \dots n
\label{eq:betacausal}
\end{equation}\]</span></p>
<p>Fortunately, there is a small set of assumptions that indeed lead to such a causal interpretation. The so-called three least squares assumptions, being:</p>
<ol type="1">
<li>The conditional distribution of <span class="math inline">\(u\)</span> given <span class="math inline">\(X\)</span> has mean zero, that is, <span class="math inline">\(E(u \mid X = x) = 0\)</span>.
<ul>
<li>We also refer to this assumption as the <strong>conditional mean independence</strong> assumption</li>
<li>This assumption implies that <span class="math inline">\(\hat{\beta_1}\)</span> is truly <em>unbiased</em></li>
</ul></li>
<li><span class="math inline">\((X_i,Y_i), i =1 \ldots n\)</span> are i.i.d.
<ul>
<li>This is true if <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span> are collected by simple random sampling</li>
<li>This delivers the sampling distribution of <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span>—again with a relatively large number (say <span class="math inline">\(n &gt; 50\)</span>) the sampling distribution can very well be approximated by a normal distribution</li>
</ul></li>
<li>Large outliers in <span class="math inline">\(X\)</span> and/or <span class="math inline">\(Y\)</span> are rare.
<ul>
<li>Outliers can result in meaningless values of <span class="math inline">\(\hat{\beta_1}\)</span></li>
</ul></li>
</ol>
<p>We will first discuss these three least squares assumptions and then give some other assumptions (but not directly necessary for the identification of causal effects) as well as you frequently encounter them</p>
<section id="least-squares-assumption-1-conditional-mean-independence" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="least-squares-assumption-1-conditional-mean-independence"><span class="header-section-number">2.4.1</span> Least squares assumption 1: conditional mean independence</h3>
<p>This first assumption states that <span class="math inline">\(E(u \mid X = x) = 0\)</span> and is conceptually the most difficult one to grasp. Loosely speaking, it states that the regression error <span class="math inline">\(u\)</span> is <em>not</em> related with the independent variable <span class="math inline">\(X\)</span>. They are independent of other. Another way of looking at this is displayed in <a href="#fig-ass1" class="quarto-xref">Figure&nbsp;<span>2.8</span></a>. Here, whatever the value of student-teacher ratio is, the expectation of the outcome variable (test scores) is always centered around the population regression line. So, on average, you always predict correctly according to <em>your</em> model, for each value of <span class="math inline">\(X\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-ass1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ass1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./figures/Lecture1_sheet25.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ass1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.8: Condition mean independence assumption
</figcaption>
</figure>
</div>
</div>
</div>
<p>So, when is this assumption violated? For example, consider again the population regression model: <span class="math inline">\(TestScore_i = \beta_0 + \beta_1 STR_i + u_i\)</span>, where <span class="math inline">\(u_i\)</span> denotes other factors. Now, these other factors can be everything and else. And you should ask yourself whether it is plausible that <span class="math inline">\(E(u|X = x) = 0\)</span> for <strong>all</strong> these other factors?</p>
<p>This assumption lies as well at the heart of experimental settings. Namely, consider a theoretical ideal randomized controlled experiment, where:</p>
<ol type="1">
<li><span class="math inline">\(X\)</span> is <em>randomly</em> assigned to people (students randomly assigned to different size classes or patients randomly assigned to medical treatments).</li>
<li>Because <span class="math inline">\(X\)</span> is assigned randomly, all other individual characteristics—the things that make up <span class="math inline">\(u\)</span>—are <em>independently</em> distributed of <span class="math inline">\(X\)</span> by definition.</li>
<li>Thus it automatically follows that: <span class="math inline">\(E(u \mid X = x) = 0\)</span></li>
</ol>
<p>Now, both in actual experiments, or with <strong>observational</strong> data, we will need to think hard about whether <span class="math inline">\(E(u|X = x) = 0\)</span> holds. <a href="multivariate.html" class="quarto-xref"><span>Chapter 3</span></a> and <a href="assessment.html" class="quarto-xref"><span>Chapter 4</span></a> provide various examples where this assumption is violated. However, if this assumption is violated it means that you have a <strong>biased</strong> inference, which boils down to the fact that your estimated <span class="math inline">\(\hat{\beta_1}\)</span> is not the one that you want and that correct inference based upon this estimate cannot be done.</p>
</section>
<section id="least-squares-assumption-2-independenty-and-identically-distributed" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="least-squares-assumption-2-independenty-and-identically-distributed"><span class="header-section-number">2.4.2</span> Least squares assumption 2: independenty and identically distributed</h3>
<p>The second least squares assumptions deals with actual sampling of your data, both the dependent (<span class="math inline">\(Y\)</span>) and independent (<span class="math inline">\(X\)</span>) variables. That entails that <span class="math inline">\((X_i,Y_i), i = 1 \dots n\)</span> should be <em>i.i.d.</em>. This assumptions arises automatically if the entity (individual, district) is sampled by simple <em>random sampling</em>. There are quite some possible violations to this assumption. For example, you sample via your friends on social media (snowballing), or observations are not independent but are correlated, which arises very frequently in the context of temporal correlation or spatial correlation.</p>
<p>The consequence of violating the <em>i.i.d.</em> assumption is less severe then violating the conditional mean independence assumption. It leads to wrong <em>standard errors</em>, not to biased estimations.</p>
</section>
<section id="least-squares-assumption-3-large-outliers-are-rare" class="level3" data-number="2.4.3">
<h3 data-number="2.4.3" class="anchored" data-anchor-id="least-squares-assumption-3-large-outliers-are-rare"><span class="header-section-number">2.4.3</span> Least squares assumption 3: Large outliers are rare</h3>
<p>The third and final least square assumption for causal inference is that large outliers are rare. Large outliers are not well defined and depend on the size of both <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>, but in general it can be seen as an <em>extreme</em> value of <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span>. The problem is that such a large outlier can strongly <em>influence</em> the results and in general it can be stated that OLS can be rather sensitive to an outlier. Consider the two population regression lines in <a href="#fig-outlier" class="quarto-xref">Figure&nbsp;<span>2.9</span></a>. The flat one (with <span class="math inline">\(\hat{\beta}_1 = 0)\)</span> does not take the isolated observation in the upper right corner into account. The one with the positive slope does. Now, clearly the one isolated observation in the upper right corner matters to a large extent and is an important driver for the results of the ordinary least squares estimator.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-outlier" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-outlier-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./figures/Lecture1_sheet29.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-outlier-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.9: Effect of outliers on OLS estimations
</figcaption>
</figure>
</div>
</div>
</div>
<p>However, this does not automatically entail that the isolated observation should be deleted. What it does entail is that one should go back to her data and investigate whether the outlier could be a mistake—perhaps a typo made when preparing the data or something that went amiss when converting the data from an <code>Excel</code> format to a <code>R</code> format.</p>
</section>
</section>
<section id="other-least-squares-assumptions" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="other-least-squares-assumptions"><span class="header-section-number">2.5</span> Other least squares assumptions</h2>
<p>Oftentimes, two other least squares assumptions are frequently encountered. However, keep in mind that you do <em>not</em> need them for causal inference. They are the assumptions of homoskedasticity and normality.</p>
<section id="homoskedasticity" class="level3" data-number="2.5.1">
<h3 data-number="2.5.1" class="anchored" data-anchor-id="homoskedasticity"><span class="header-section-number">2.5.1</span> Homoskedasticity</h3>
<p>Homoskedasticity is concerned with the standard errors. Its definition is if <span class="math inline">\(var(u \mid X=x)\)</span> is constant—that is, if the variance of the conditional distribution of <span class="math inline">\(u\)</span> given <span class="math inline">\(X\)</span> does not depend on <span class="math inline">\(X\)</span>—then <span class="math inline">\(u\)</span> is said to be homoskedastic. Otherwise, <span class="math inline">\(u\)</span> is heteroskedastic.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-homoskedasticity" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-homoskedasticity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./figures/Sheet21.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-homoskedasticity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.10: Homoskedastic standard errors
</figcaption>
</figure>
</div>
</div>
</div>
<p>Consider <a href="#fig-homoskedasticity" class="quarto-xref">Figure&nbsp;<span>2.10</span></a>. Clearly the variance <em>around</em> the population regression line is everywhere the same, regardless the value of student-teacher ratio (<span class="math inline">\(X\)</span>). Recall, that <span class="math inline">\(E(u \mid X=x) = 0\)</span> so <span class="math inline">\(u\)</span> satisfies Least Squares Assumption 1. Now, in addition we also assume that the variance of <span class="math inline">\(u\)</span> does not depend on <span class="math inline">\(x\)</span>. This is the case of homoskedasticity</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-heteroskedasticity" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-heteroskedasticity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./figures/Sheet22.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-heteroskedasticity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.11: Heteroskedastic standard errors
</figcaption>
</figure>
</div>
</div>
</div>
<p>Now consider <a href="#fig-heteroskedasticity" class="quarto-xref">Figure&nbsp;<span>2.11</span></a>. Now clearly the variance around the population regression line increases in size of student-teacher ratio (<span class="math inline">\(X\)</span>). So, <span class="math inline">\(E(u \mid X=x) = 0\)</span> is still satisfied, but the variance of <span class="math inline">\(u\)</span> does now depend on <span class="math inline">\(x\)</span>. <span class="math inline">\(u\)</span> is now said to be heteroskedastic.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-wages" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-wages-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./figures/Sheet23.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-wages-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.12: Wages versus years of education
</figcaption>
</figure>
</div>
</div>
</div>
<p>Very often data in the social sciences are heteroskedastic. For example, wages are usually heteroskedastic in the amount of education consumed. <a href="#fig-wages" class="quarto-xref">Figure&nbsp;<span>2.12</span></a> shows the relation between years of education and wages, and the larger the years of education the larger hourly earnings (wages) are—as you would assume it should be. But the variance also increases in years of education. That is because you can easily predict wages when workers enjoyed very few years of schooling—usually those are just above minimum wages—but the spread becomes much wider when years of schooling go up.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-heteroskedasticityca" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-heteroskedasticityca-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./figures/Sheet24.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-heteroskedasticityca-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.13: Heteroskedasticity in Californation schools?
</figcaption>
</figure>
</div>
</div>
</div>
<p>Is this now the case for our Californian school dataset. If we look again at the scatterplot between test scores and student-teacher ratios in <a href="#fig-heteroskedasticityca" class="quarto-xref">Figure&nbsp;<span>2.13</span></a>, then that is very difficult to see. But then again, does it matter whether you face heteroskedasticity or homoskedasticity.?</p>
<p>Note that so far we have (without saying so) assumed that <span class="math inline">\(u\)</span> might be heteroskedastic Recall again the three least squares assumptions:</p>
<ol type="1">
<li><span class="math inline">\(E(u \mid X = x) = 0\)</span></li>
<li><span class="math inline">\((X_i,Y_i), i =1,\ldots,n\)</span>, are i.i.d.</li>
<li>Large outliers are rare</li>
</ol>
<p>They do not say anything about homo- or heteroskedasticity and because we have not explicitly assumed homoskedastic errors, we have implicitly allowed for heteroskedasticity.</p>
<p>But what if the errors are in fact homoskedastic? Then in fact you can prove that OLS has the lowest variance among estimators that are <em>linear</em> in <span class="math inline">\(Y\)</span>. The formula for the variance of <span class="math inline">\(\hat{\beta_1}\)</span> and the OLS standard error simplifies: If <span class="math inline">\(var(u_i \mid X_i=x) = \sigma_u^2\)</span>, then <span class="math display">\[\begin{equation}
    var(\hat{\beta}_1) = \frac{\sigma_u^2}{n\sigma_X^2}
    \label{eq:olssesimple}
\end{equation}\]</span> which is much simpler than Eq. <span class="math inline">\(\ref{eq:olsse}\)</span>. Again note that <span class="math inline">\(var(\hat{\beta}_1)\)</span> is inversely proportional to <span class="math inline">\(var(X)\)</span>: more spread in <span class="math inline">\(X\)</span> means more information about <span class="math inline">\(\hat{\beta}_1\)</span>—we discussed this earlier but it is clearer from this formula.</p>
<p>But what does this mean for estimation. Note that <code>R</code> does not automatically apply Eq. <span class="math inline">\(\ref{eq:olsse}\)</span> for its standard errors, but uses the simpler version Eq. <span class="math inline">\(\ref{eq:olssesimple}\)</span> instead. But if we invoke the <code>vcovHC</code> command, <code>R</code> computes heteroskedasticity-robust standard errors. So if you do not, <code>R</code> computes homoskedasticity-only standard errors. So:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vcovHC</span>(model_2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                  (Intercept) factor(large)TRUE
(Intercept)          1.578968         -1.578968
factor(large)TRUE   -1.578968          3.349843</code></pre>
</div>
</div>
<p>where the variances are now on the diagonal and thus the standard error of <code>large</code> is <span class="math inline">\(\sqrt{3.35}\)</span>.</p>
<p>The bottom line is that the errors are either homoskedastic or heteroskedastic and if you use heteroskedastic-robust standard errors, you are fine. Namely:</p>
<ol type="1">
<li>If the errors are heteroskedastic and you use the homoskedasticity-only formula for standard errors, your standard errors will be wrong (the homoskedasticity-only estimator of the variance of <span class="math inline">\(\hat{\beta}_1\)</span> is inconsistent if there is heteroskedasticity).</li>
<li>The two formulas coincide (when <span class="math inline">\(n\)</span> is large) in the special case of homoskedasticity.</li>
<li>So, you should <strong>always</strong> use heteroskedasticity-robust standard errors.</li>
</ol>
</section>
<section id="normal-distributed-regression-term" class="level3" data-number="2.5.2">
<h3 data-number="2.5.2" class="anchored" data-anchor-id="normal-distributed-regression-term"><span class="header-section-number">2.5.2</span> Normal distributed regression term</h3>
<p>Finally, in many introductionary statistic courses, normal distributed error terms are assumed, which facilitates testing with small samples. So, <span class="math inline">\(u\)</span> should be distributed <span class="math inline">\(N(0,\sigma^2)\)</span>. If you have a reasonable amount of observations (<span class="math inline">\(n &gt;50\)</span>), you do not need this assumption, and especially not for causal inference.</p>
</section>
</section>
<section id="measures-of-fit" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="measures-of-fit"><span class="header-section-number">2.6</span> Measures of fit</h2>
<p>A natural question that might arise is how well the population regression line fits or explains the data. For ordinary least squares estimators often two regression statistics are given that provide complementary measures of the quality of fit:</p>
<ol type="1">
<li>The regression <strong><span class="math inline">\(R^2\)</span></strong>: This measures the fraction of the variance of <span class="math inline">\(Y\)</span> that is explained by <span class="math inline">\(X\)</span>; it is unitless and ranges between zero (no fit) and one (perfect fit). This one is almost always reported.</li>
<li>The standard error of the regression <strong><span class="math inline">\(SER\)</span></strong>: This measures the magnitude of a typical regression residual in the units of <span class="math inline">\(Y\)</span>.</li>
</ol>
<section id="the-regression-r2" class="level3" data-number="2.6.1">
<h3 data-number="2.6.1" class="anchored" data-anchor-id="the-regression-r2"><span class="header-section-number">2.6.1</span> The regression R<span class="math inline">\(^2\)</span></h3>
<p>The regression R<span class="math inline">\(^2\)</span> is the fraction of the sample variance of <span class="math inline">\(Y_i\)</span> “explained” by the regression. To see this, first note that <span class="math inline">\(Y_i = \hat{Y}_i + \hat{u}_i\)</span> or the observation is equal to the OLS prediction plus the predicted residual. In this notation, the R<span class="math inline">\(^2\)</span> is the ratio between the sample variance of <span class="math inline">\(\hat{Y}\)</span> and the sample variance of <span class="math inline">\(Y\)</span>. Here we make use of the following equity: Total sum of squares = explained “SS” + Residual “SS”—or, <span class="math inline">\(TSS = ESS + RSS\)</span>—, where we can now define R<span class="math inline">\(^2\)</span> as:</p>
<p><span class="math display">\[\begin{equation}
\text{R}^2= \frac{ESS}{TSS} = \frac{\sum^n_{i=1}\left(\hat{Y}_i - \overline{Y}\right)^2}{\sum^n_{i=1}\left(Y_i - \overline{Y}\right)^2}.
\label{eq:r2}
\end{equation}\]</span> Now if R<span class="math inline">\(^2 = 0\)</span> then that means <span class="math inline">\(ESS = 0\)</span> and if R<span class="math inline">\(^2 = 1\)</span> then that means <span class="math inline">\(ESS = TSS\)</span>. So, by definition yields <span class="math inline">\(0 \leq \text{R}^2 \leq 1\)</span>. There is one additional remark to make and that is that for an univariate regression model (so with one single <span class="math inline">\(X\)</span> on the right side), R<span class="math inline">\(^2\)</span> equals the square of the correlation coefficient between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p>
</section>
<section id="the-standard-error-of-the-regression" class="level3" data-number="2.6.2">
<h3 data-number="2.6.2" class="anchored" data-anchor-id="the-standard-error-of-the-regression"><span class="header-section-number">2.6.2</span> The Standard Error of the Regression</h3>
<p>The standard error of the regression is defined as:</p>
<p><span class="math display">\[\begin{equation}
SER = \sqrt{\frac{1}{n-2} \sum_{i=1}^n \hat{u}_i^2}
\label{eq:ser}
\end{equation}\]</span></p>
<p>In comparison with the <span class="math inline">\(R^2\)</span>, the <span class="math inline">\(SER\)</span> is measured in the units of <span class="math inline">\(u\)</span>, which are actually the units of <span class="math inline">\(Y\)</span>. It measures the average “size” of the OLS residual (so the average ‘mistake’ made by the OLS regression line in absolute terms).</p>
<p>However, more often the <em>root mean squared error</em> (<span class="math inline">\(RMSE\)</span>) is used, which is very closely related to the <span class="math inline">\(SER\)</span>: <span class="math display">\[\begin{equation}
RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^n \hat{u}_i^2},
\label{eq:rmse}
\end{equation}\]</span> where <span class="math inline">\(RMSE\)</span> only differs from the <span class="math inline">\(SER\)</span> in the <em>degrees of freedom</em>.</p>
<p>If we again look at our regression output:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = testscr ~ str, data = CASchools)

Residuals:
    Min      1Q  Median      3Q     Max 
-47.727 -14.251   0.483  12.822  48.540 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 698.9329     9.4675  73.825  &lt; 2e-16 ***
str          -2.2798     0.4798  -4.751 2.78e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 18.58 on 418 degrees of freedom
Multiple R-squared:  0.05124,   Adjusted R-squared:  0.04897 
F-statistic: 22.58 on 1 and 418 DF,  p-value: 2.783e-06</code></pre>
</div>
</div>
<p>then we see that the <span class="math inline">\(R^2 = .05\)</span>. So, only 5% of all variation in test scores is explained. This of course makes sense as potential many important variables are not included in the model. However, this does not automatically mean that the impact is biased and especially that the <span class="math inline">\(STR\)</span> is unimportant in a policy sense. Again, we focus on causal inference, not on making a good model for prediction. The <span class="math inline">\(SER= 18.6\)</span> (given here as <code>Residual standard error</code>) indicates that the average error made is 18.6 test score units, which can be seen as sizable. In <a href="multivariate.html" class="quarto-xref"><span>Chapter 3</span></a> we include other, and important, variables and what we then of course will see is that the R<span class="math inline">\(^2\)</span> increases and the <span class="math inline">\(SER\)</span> decreases.</p>
</section>
</section>
<section id="conclusion" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">2.7</span> Conclusion</h2>
<p>Regression analysis in the most common form of statistical analysis over the sciences. Very often is it used to model associations. However, in applied econometrics regression analysis is applied to find causal causal relations. This can be done on the basis of three assumptions, of which the first—the conditional mean assumption—is the most crucial. In fact, if this assumption holds then the data mimics the data that come out of an experiment. This assumption can unfortunately not be proven. We therefore have to think very hard whether this assumption holds. The next Chapter deals with a possible violation of this assumption, how to solve for it and at the same time we answer the question why we want multiple variables in our specification.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-amrhein2019scientists" class="csl-entry" role="listitem">
Amrhein, Valentin, Sander Greenland, and Blake McShane. 2019. <span>“Scientists Rise up Against Statistical Significance.”</span> Nature Publishing Group.
</div>
<div id="ref-galton1886regression" class="csl-entry" role="listitem">
Galton, Francis. 1886. <span>“Regression Towards Mediocrity in Hereditary Stature.”</span> <em>The Journal of the Anthropological Institute of Great Britain and Ireland</em> 15: 246–63.
</div>
<div id="ref-senn2011francis" class="csl-entry" role="listitem">
Senn, Stephen. 2011. <span>“Francis Galton and Regression to the Mean.”</span> <em>Significance</em> 8 (3): 124–26.
</div>
<div id="ref-stock2003introduction" class="csl-entry" role="listitem">
Stock, James H, Mark W Watson, et al. 2003. <em>Introduction to Econometrics</em>. Vol. 104. Addison Wesley Boston.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>This is something that should be extensively dealt with in introductory statistics courses.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Modern statisticians actually see this as a form of shrinkage.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>This result is given but is not all too difficult to prove. However, usually you do need these types of equations in your work.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./intro.html" class="pagination-link" aria-label="Introduction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./multivariate.html" class="pagination-link" aria-label="Modeling in the Social Sciences">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Modeling in the Social Sciences</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>